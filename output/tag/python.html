<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Dimitris Rongotis - python</title>
        <link rel="stylesheet" href="http://localhost:8000/theme/css/main.css" />
        <link href="http://localhost:8000/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Dimitris Rongotis Atom Feed" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
<a href="https://github.com/dimr">
<img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub" />
</a>
        <header id="banner" class="body">
                <h1><a href="http://localhost:8000/">Dimitris Rongotis  <strong>Programming stuff, notes and thoughts</strong></a></h1>
                <nav><ul>
                    <li><a href="/archives.html">Archives</a></li>
                    <li><a href="/tags.html">Tags</a></li>
                    <li><a href="http://localhost:8000/pages/about.html">About</a></li>
                    <li><a href="http://localhost:8000/category/posts.html">posts</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="http://localhost:8000/scraping-for-houses.html">Scraping for houses-part 1</a></h1>
<footer class="post-info">
        <abbr class="published" title="2016-06-15T04:47:56+03:00">
                Published: Wed 15 Jun 2016
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://localhost:8000/author/dimitris.html">dimitris</a>
        </address>
<p>In <a href="http://localhost:8000/category/posts.html">posts</a>.</p>
<p>tags: <a href="http://localhost:8000/tag/python.html">python</a> <a href="http://localhost:8000/tag/scrapy.html">scrapy</a> <a href="http://localhost:8000/tag/tutorial.html">tutorial</a> </p>
</footer><!-- /.post-info --><p>This is the first part of a tutorial series i am planning to write about the process of
acquiring data,cleaning data,analyzing data and visualizing. In this first part, i will show how to
scrape data from a  greek real estate website.</p>
<p>We are going to use <a href="http://scrapy.org/">scrapy</a>, a famous python library for screen scraping and i will use <a href="https://en.wikipedia.org/wiki/XPath">xpath</a>, a powerful query language for selecting nodes in xml/html documents.
For the full python code of this part, please visit this link.</p>
<blockquote>
<p>XPath uses path expressions to select nodes or node-sets in an XML document. The node is selected by following a path or steps.</p>
</blockquote>
<p>i am going to assume that you have a basic knowledge of python and you can install additional libraries with pip.</p>
<h4>Some general information about scraping</h4>
<ol>
<li>
<p>First things first, when you want to scrape a website the first thing to do is disable javascript from the browser. Scrapy does <strong>not</strong> load it for you, with disabled javascript you see what scrapy sees when it visits the page. For example, if you check the page of a <a href="http://www.homegreekhome.com/en/rent_Apartment_Rigilis__Athens_-l3589786">random house</a> at homegreekhome.com you will
see that pictures are not shown. There are ways to parse elements loaded via javascript by using either <a href="http://www.seleniumhq.org/">selenium webdriver</a> with a normal browser like Firefox or with a headless browser like <a href="http://phantomjs.org/">Phantom.js</a> or like <a href="https://splash.readthedocs.io/en/stable/">splash browser</a>.</p>
</li>
<li>
<p>Google chrome dev tools is your friend. It has some a really super helpful tool that you can use to extract the xpath of any element that you want to extract.</p>
</li>
</ol>
<h4>The thing to start first</h4>
<p>Assuming that you have installed scrapy correctly, lets first check a webpage. I will search for houses that are in the center of Athens.</p>
<div class="highlight"><pre><span></span><span class="n">scrapy</span> <span class="n">shell</span> <span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="o">.</span><span class="n">homegreekhome</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">en</span><span class="o">/</span><span class="n">search</span><span class="o">/</span><span class="n">results</span><span class="o">/</span><span class="n">residential</span><span class="o">/</span><span class="n">rent</span><span class="o">/</span><span class="n">r100</span><span class="o">/</span><span class="n">m100m</span><span class="err">?</span><span class="n">ref</span><span class="o">=</span><span class="n">homepageMapSearchSR</span>
</pre></div>


<p>and you will see info printed out. The basic idea is that scrapy loaded the page that you requests and you have the a response object with various attributes.
then copy paste this. Explanation follows</p>
<div class="highlight"><pre><span></span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;searchDetailsListings&quot;]/div[1]/div/div/div[1]/div/h4/a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
<span class="p">[</span><span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Nosokomeio_Pedon__Athens_-l4546456?ref=searchListViewLD&#39;</span><span class="p">]</span>
</pre></div>


<p>and you got the link of the first house listed. The way to do it is to open the google chrome dev tools, select the element you want, right click and select copy xpath.</p>
<p><img src="http://localhost:8000/images/scraping/first_pic.png" width="760"></p>
<p>here is how to get them all</p>
<div class="highlight"><pre><span></span><span class="n">response</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;searchDetailsListings&quot;]//div/div/div/div[1]/div/h4/a/@href&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">extract</span><span class="p">()</span>
</pre></div>


<p>and you get</p>
<div class="highlight"><pre><span></span><span class="p">[</span><span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Fokionos_Negri__Athens_-l4537141?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Pedion_Areos__Athens_-l4501809?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Ampelokipoi__Athens_-l4505771?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Alsos_Pagkratiou__Athens_-l4485866?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Plateia_Koliatsou__Athens_-l4554881?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Kipseli__Athens_-l4535603?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Plaka__Athens_-l4297290?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Kolonaki__Athens_-l4550968?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Kolonaki__Athens_-l4547891?ref=searchListViewLD&#39;</span><span class="p">,</span>
 <span class="sa">u</span><span class="s1">&#39;http://www.homegreekhome.com/en/rent_Apartment_Agios_Ioannis__Athens_-l2432021?ref=searchListViewLD&#39;</span><span class="p">]</span>
</pre></div>


<p>Notice the difference between the first call and the second. We replaced <code>**/div[1]**</code> with <code>**//div**</code> and we got all this links. In xpath's world, when you write <code>div[1]</code> you get the first div element
after <code>**[@id="searchDetailsListings"]**</code> while <code>//</code> gets all the elements that are nested inside the previous element. Xpath is powerful, it may take you some time to get used to it, but it is word the try.</p>
<p>When the spider starts collecting the data it needs to store them in a data structure somewhere in the project. This is a simple as writing the fields that you choose to collect. In our example, these are the fields that we need to  set in our items.py filename</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14</pre></div></td><td class="code"><div class="highlight"><pre><span></span>  <span class="k">class</span> <span class="nc">HousesItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
  <span class="c1"># define the fields for your item here like:</span>
        <span class="n">price</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">url</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">construction_year</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">heating_system</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">floor</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">house_type</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s1">&#39;Appartment&#39;</span><span class="p">)</span>
        <span class="n">area</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">longitude</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">latitude</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">bathrooms</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">pics</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
        <span class="n">phone</span><span class="o">=</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre></div>
</td></tr></table>

<p>Notice that we also scraped the coordinates of each house and the pics and the phone number that requires a bit more advanced operation that probably requires a different post. However, pics and coordinates although not visible to where hardcoded in each webpage and it was as simple as searching for the them in the html document to acquire them.</p>
<h4>Follow all pages</h4>
<p>However, we do not want to get only the first page of the search results, we want all of them. The way to do it is to set a Rule. In essence, we want to tell scrapy to simulate a behavior where it presses the
next button at the bottom of the page and scrape next page until there is not page at all. As we did before, you can get xpath from google chrome.</p>
<p><img src="http://localhost:8000/images/scraping/follow.png" width="760"></p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10</pre></div></td><td class="code"><div class="highlight"><pre><span></span><span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1">#Athens Center</span>
    <span class="s1">&#39;http://www.homegreekhome.com/en/search/results/residential/rent/r100/m100m/&#39;</span><span class="p">,</span>
    <span class="c1">#Thessaloniki Center</span>
    <span class="c1">#&#39;http://www.homegreekhome.com/en/search/results/residential/rent/r108/m108m&#39;</span>
<span class="p">]</span>

<span class="n">rules</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">Rule</span><span class="p">(</span><span class="n">LinkExtractor</span><span class="p">(</span><span class="n">allow</span><span class="o">=</span><span class="p">(),</span><span class="n">restrict_xpaths</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;pagination&quot;]/ul/li[8]/a&#39;</span><span class="p">)</span> <span class="p">)</span> <span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="s1">&#39;parse_item&#39;</span><span class="p">,</span> <span class="n">follow</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</td></tr></table>

<p>The <code>start_urls</code> list tells from which pages to start, as you can see but just adding a second line from another city or another area in Athens you will get all the houses. Pretty cools, indeed.</p>
<h4>Parse information for each house</h4>
<p>However, we need information for each house. We need to get the price and all the other information that are under the <code>"Key features"</code> on each house webpage. You continue the same way, you select the element and copy its xpath. Instead of going back to your scrapy shell each time you copy the xpath you can actually test in google`s chrome console.</p>
<p>For example if you paste the following expression in the console of this <a href="http://www.homegreekhome.com/en/rent_Apartment_Pedion_Areos__Athens_-l4501809?ref=searchListViewLD">page</a></p>
<div class="highlight"><pre><span></span><span class="nx">$x</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;listingDetailsMainContent&quot;]/div[9]/div[1]/div[2]/span&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>


<p><img src="http://localhost:8000/images/scraping/chrome_console.png" width="760"></p>
<p>The process of extracting the information you want to keep from each house is somewhat similar. You select the time, get its xpath expression and you pass it scrapy's response object.
You can see the source code of this project <code>HERE</code>. Getting familiar with scrapy's project structure is something that you can learn by reading its excellent documentation. You can see how you start a project, where are you settings, how do you save the data that you parse etc.</p>
<h4>Some important things</h4>
<ul>
<li>I used here xpath, in the scrapy world these are called <a href="http://doc.scrapy.org/en/latest/topics/selectors.html">selectors</a>. You can also parse html elements by CSS. Choose whatever you feel more comfortable with.  <a href="http://www.zvon.org/comp/r/tut-XPath_1.html">This</a> a very good xpath tutorial.</li>
<li>When scraping you should not hit the website hard. By default, scrapy follows the robots.txt directives of each site it visits but you can also tell it to ignore them. Be sure to enable the <a href="http://doc.scrapy.org/en/latest/topics/autothrottle.html">AutoThrottle</a> extension and that you set the AUTOTHROTTLE_ENABLED to True. Try to limit your requests at 1 page every 3-4 seconds or you can get your IP banned. If you really need your data fast, you can use <a href="http://doc.scrapy.org/en/latest/topics/downloader-middleware.html?highlight=proxy#std:reqmeta-proxy">proxies</a> that are easily configurable.</li>
</ul><p>There are <a href="http://localhost:8000/scraping-for-houses.html#disqus_thread">comments</a>.</p>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="http://localhost:8000/debsnap-cli.html" rel="bookmark"
                           title="Permalink to Debian snapshot repository cli tool">Debian snapshot repository cli tool</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-05-18T04:47:56+03:00">
                Published: Wed 18 May 2016
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="http://localhost:8000/author/dimitris.html">dimitris</a>
        </address>
<p>In <a href="http://localhost:8000/category/posts.html">posts</a>.</p>
<p>tags: <a href="http://localhost:8000/tag/debian.html">debian</a> <a href="http://localhost:8000/tag/linux.html">linux</a> <a href="http://localhost:8000/tag/debsnapshot.html">debsnapshot</a> <a href="http://localhost:8000/tag/python.html">python</a> </p>
</footer><!-- /.post-info -->                <p>debsnapshot repository command line tool</p>
                <a class="readmore" href="http://localhost:8000/debsnap-cli.html">read more</a>
<p>There are <a href="http://localhost:8000/debsnap-cli.html#disqus_thread">comments</a>.</p>                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
                </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="http://localhost:8000/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                            <li><a href="https://github.com/dimr">github</a></li>
                            <li><a href="https://twitter.com/dim__r">twitter</a></li>
                            <li><a href="/feeds/all.atom.xml">rss</a></li>
                            <li><a href="mailto:dimitris.rongotis@gmail.com">envelope-o</a></li>
                            <li><a href="http://www.vimeo.com">vimeo</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

<script type="text/javascript">
    var disqus_shortname = 'dmtrsblog';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>